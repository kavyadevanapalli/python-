{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is my dataset\n",
    "data = pd.read_csv(\"file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps identify the dublicates for a perticular column variable\n",
    "# sorting the values based on that perticular column\n",
    "data.sort_values(\"column_name\", inplace = True)\n",
    "# identify the dublicates in that column \n",
    "bool_series = data[\"column_name\"].duplicated(keep = \"first\")  # this will consider the first value as unique and treat the remaining ones as dublicates\n",
    "# in bool_series, true shows the duplicate values and false shows the unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove the dublicates\n",
    "# passing NOT of bool series to see unique values only \n",
    "data = data[~bool_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to identify the dublicates in entire dataset\n",
    "bool_series = data.duplicated(keep = \"first\")\n",
    "# to remove the dublicates\n",
    "# passing NOT of bool series to see unique values only \n",
    "data = data[~bool_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or dublicates can be removed using drop_dublicates method\n",
    "data.drop_dublicates(subset = \"column_name\", keep = \"first\", inplace = True) # this will keep the first value and removes all remaining dublicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimentionality reduction in machine learning\n",
    "\n",
    "Dimentionality reduction is the transformation of data from a \n",
    "high-dimensional space into a low-dimensional space with out loosing much information.\n",
    "In machine learning, we train the model with data which contains features (no of features = no of dimentions).\n",
    "if the features are high in number, it is  harder to visualize and then work on it. \n",
    "Sometimes, some of these features are correlated, in that case we can not consider all of them \n",
    "for training the model. This is where dimensionality \n",
    "reduction algorithms come into play. Most commenly used method for dimentionality reduction is principle component\n",
    "analysis (PCA). In PCA, the dimentions are reduced by using eigen values and eigen vectors. \n",
    "Eigenvectors corresponding to the largest eigenvalues will cover the most of the variance of the dataset.\n",
    "we need to select the no of eigenvectors with lage value of eigenvalue so that most of the variance of our dataset\n",
    "should be covered. Then, we will project our datapoints on to the selected eigenvectors (which are called principle components). Finally, we will get the dataset with less features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
